{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initializing torch device according to hardware available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a dataset object to use as input on a CNN\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transforms=None):\n",
    "        \"\"\"\n",
    "        Default initializer\n",
    "        :param root: path to dataset root\n",
    "        :param transforms: optional list of transforms\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "\n",
    "        # Load images filelist\n",
    "        self.images = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
    "        # Load annotations filelist\n",
    "        self.annotations = list(sorted(os.listdir(os.path.join(root, \"annotations\"))))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Default getter for dataset objects\n",
    "        :param index: index of the wanted image + annotation\n",
    "        :return: image as PIL Image and target dictionary\n",
    "        \"\"\"\n",
    "        return self.__load_image(index), self.__generate_target(index)\n",
    "\n",
    "    def __load_image(self, index):\n",
    "        \"\"\"\n",
    "        Load an image from the list of available images\n",
    "        :param index: index of the wanted image\n",
    "        :return: the image as a PIL.Image object\n",
    "        \"\"\"\n",
    "        image_path = os.path.join(self.root, \"images\", self.images[index])\n",
    "        return Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    def __load_annotation(self, index):\n",
    "        \"\"\"\n",
    "        Load image annotations from the list of available annotations files\n",
    "        :param index: index of the wanted image\n",
    "        :return: the annotations as a dict\n",
    "        \"\"\"\n",
    "        annotation_path = os.path.join(self.root, \"annotations\", self.annotations[index])\n",
    "        with open(annotation_path, \"r\") as fp:\n",
    "            annotation_json = json.load(fp)\n",
    "            fp.close()\n",
    "        return [value for key, value in annotation_json.items() if \"item\" in key]\n",
    "\n",
    "    def __generate_target(self, index):\n",
    "        \"\"\"\n",
    "        Generate the target dict according to Torch specification\n",
    "        :param index: index of the wanted annotations\n",
    "        :return: target dict\n",
    "        \"\"\"\n",
    "        annotations = self.__load_annotation(index)\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        isCrowd = torch.zeros((len(annotations),), dtype=torch.int64)\n",
    "        for annotation in annotations:\n",
    "            boxes.append(annotation[\"bounding_box\"])\n",
    "            labels.append(annotation[\"category_id\"])\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32, device=device)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64, device=device)\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        return {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": torch.tensor([index], device=device),\n",
    "            \"area\": area,\n",
    "            \"isCrowd\": isCrowd\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = CustomDataset(\"../data/assignment_1/train\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
